{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TMJYlw9bo1qC"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from torchvision import datasets,transforms\n",
        "# from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "t8P-VwcapV3R"
      },
      "outputs": [],
      "source": [
        "# transform_train = transforms.Compose([\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.RandomRotation(10),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "# ])\n",
        "\n",
        "# # Normalize the test set same as training set without augmentation\n",
        "# transform_test = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "# ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwV3LsHCpQzK",
        "outputId": "c3e17d30-9191-4879-845e-010bed3f5dfb"
      },
      "outputs": [],
      "source": [
        "# train_data=datasets.CIFAR10('data',train=True,download=True,transform=transform_train)\n",
        "# test_data=datasets.CIFAR10('data',train=False,download=True,transform=transform_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FgXKXmf-pfOp"
      },
      "outputs": [],
      "source": [
        "\n",
        "# num_workers=0\n",
        "# batch_size=50\n",
        "# valid_size=0.2\n",
        "# train_length = len(train_data)\n",
        "# indices=list(range(len(train_data)))\n",
        "# split = int(np.floor(valid_size * train_length))\n",
        "\n",
        "# np.random.shuffle(indices)\n",
        "\n",
        "# train_idx=indices[split:]\n",
        "# valid_idx=indices[:split]\n",
        "\n",
        "# train_sampler=SubsetRandomSampler(train_idx)\n",
        "# validation_sampler=SubsetRandomSampler(valid_idx)\n",
        "\n",
        "# train_loader=DataLoader(train_data,num_workers=num_workers,batch_size=batch_size,sampler=train_sampler)\n",
        "# valid_loader=DataLoader(train_data,num_workers=num_workers,batch_size=batch_size,sampler=validation_sampler)\n",
        "# test_loader=DataLoader(test_data,shuffle=True,num_workers=num_workers,batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ie0twxAMpjvJ"
      },
      "outputs": [],
      "source": [
        "# classes=['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "#            'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# def RGBshow(img):\n",
        "#     img=img*0.5+0.5\n",
        "#     plt.imshow(np.transpose(img,(1,2,0)))\n",
        "\n",
        "# fig=plt.figure(1,figsize=(30,5))\n",
        "# for idx in range(batch_size):\n",
        "#     ax=fig.add_subplot(2,batch_size/2,idx+1,xticks=[],yticks=[])\n",
        "#     RGBshow(images[idx])\n",
        "#     ax.set_title(classes[labels[idx]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "yKn3234eqC9z",
        "outputId": "f8ad7f8c-d27d-401f-9464-12b4647f7e1f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define the mean and standard deviation for CIFAR-10\n",
        "# These values are precomputed for the CIFAR-10 dataset\n",
        "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)  # Mean of the CIFAR-10 dataset\n",
        "CIFAR10_STD = (0.2470, 0.2435, 0.2616)   # Standard deviation of the CIFAR-10 dataset\n",
        "\n",
        "# Define transformations for training and testing data\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
        "    transforms.RandomCrop(32, padding=4),  # Randomly crop images with padding\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD)  # Normalize using CIFAR-10 mean and std\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD)  # Normalize using CIFAR-10 mean and std\n",
        "])\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',  # Path to store the dataset\n",
        "    train=True,  # Load the training set\n",
        "    download=True,  # Download the dataset if not already present\n",
        "    transform=train_transform  # Apply training transformations\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',  # Path to store the dataset\n",
        "    train=False,  # Load the test set\n",
        "    download=True,  # Download the dataset if not already present\n",
        "    transform=test_transform  # Apply testing transformations\n",
        ")\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 64  # You can adjust the batch size\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Check the dataset\n",
        "print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n",
        "\n",
        "# Example: Visualize a batch of images\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # Unnormalize the image\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # Convert from (C, H, W) to (H, W, C)\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print(' '.join(f'{train_dataset.classes[labels[j]]}' for j in range(batch_size)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFDitfEyq3VC",
        "outputId": "6478a685-4dc0-4c78-f299-182b4266389f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CIFAR10CNN(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=4096, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the CNN model\n",
        "class CIFAR10CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CIFAR10CNN, self).__init__()\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)  # Input: 32x32x3, Output: 32x32x32\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # Output: 16x16x32\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  # Output: 16x16x64\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # Output: 8x8x64\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)  # Output: 8x8x64\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(8 * 8 * 64, 64)  # Input: 8*8*64, Output: 64\n",
        "        self.fc2 = nn.Linear(64, 10)  # Output: 10 (for 10 classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional layers with ReLU and pooling\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "\n",
        "        # Flatten the output for the fully connected layers\n",
        "        x = x.view(-1, 8 * 8 * 64)  # Reshape to (batch_size, 8*8*64)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the model\n",
        "model = CIFAR10CNN()\n",
        "\n",
        "# Print the model summary\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2NNp_YQq5S6",
        "outputId": "0eccb14a-7a3f-492d-9931-1f27411cde86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3], Step [100/782], Loss: 1.5826\n",
            "Epoch [1/3], Step [200/782], Loss: 1.4805\n",
            "Epoch [1/3], Step [300/782], Loss: 1.4357\n",
            "Epoch [1/3], Step [400/782], Loss: 1.3889\n",
            "Epoch [1/3], Step [500/782], Loss: 1.3996\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # Loss function for classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Optimizer\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # Print every 100 mini-batches\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Training finished.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dju4-b1Kq9YK"
      },
      "outputs": [],
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():  # Disable gradient computation\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)  # Get the predicted class\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on the test set: {100 * correct / total:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
